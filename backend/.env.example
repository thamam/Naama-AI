# Server Configuration
NODE_ENV=development
PORT=5000
API_BASE_URL=http://localhost:5000

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:3000

# Database
MONGODB_URI=mongodb://localhost:27017/naama-ai

# JWT Authentication
JWT_SECRET=your-secret-key-change-this-in-production
JWT_EXPIRES_IN=7d

# Claude API (for Naama-AI backend only - won't interfere with Claude Code)
# This is separate from your Claude Code subscription
# OPTIONAL if LOCAL_HEBREW_LLM_ENABLED=true (only needed for English/fallback)
# Use scripts/set-api-key.sh for secure setup
NAAMA_CLAUDE_API_KEY=your-claude-api-key-here
CLAUDE_MODEL=claude-3-5-haiku-20241022
CLAUDE_MAX_TOKENS=2048

# Local Hebrew LLM (Phase 2 - RECOMMENDED)
# Enable local Hebrew LLM for cost-effective Hebrew content generation
# Requires Ollama with llama3.2 model (DictaLM 2.0 not yet available in Ollama registry)
# Installation: curl https://ollama.ai/install.sh | sh && ollama pull llama3.2
LOCAL_HEBREW_LLM_ENABLED=true
LOCAL_HEBREW_LLM_ENDPOINT=http://localhost:11434
LOCAL_HEBREW_LLM_MODEL=llama3.2
LOCAL_HEBREW_LLM_BACKEND=ollama
LOCAL_HEBREW_LLM_MAX_TOKENS=2048
LOCAL_HEBREW_LLM_TEMPERATURE=0.7
LOCAL_HEBREW_LLM_TIMEOUT=300000

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
